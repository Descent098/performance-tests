{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to my performance testing site This site is cataloging my collection of random performance tests. None of them are meant to be incredibly formal, but they can be informative in their own way Tests Test name Description Golang Java Python Link http-basics This test is just designed to compare a very basic HTTP server from each language Test is a simple GET on / \u2705 \u2705 \u2705 link sockets This test is just comparing a very naive and simple approach to a multithreaded HTTP server, with a hard coded result. This test doesn't provide a ton of value, besides helping me test how locust worked. Test is a simple GET on / \u2705 \u2705 \u2705 link","title":"Home"},{"location":"#welcome-to-my-performance-testing-site","text":"This site is cataloging my collection of random performance tests. None of them are meant to be incredibly formal, but they can be informative in their own way","title":"Welcome to my performance testing site"},{"location":"#tests","text":"Test name Description Golang Java Python Link http-basics This test is just designed to compare a very basic HTTP server from each language Test is a simple GET on / \u2705 \u2705 \u2705 link sockets This test is just comparing a very naive and simple approach to a multithreaded HTTP server, with a hard coded result. This test doesn't provide a ton of value, besides helping me test how locust worked. Test is a simple GET on / \u2705 \u2705 \u2705 link","title":"Tests"},{"location":"http-basics/","text":"HTTP basics This test is just designed to compare a very basic HTTP server from each language. Specifically the stack for each language is: Go: The net/http standard library https://pkg.go.dev/net/http Java: The com.sun.net.httpserver \"standard\" library https://docs.oracle.com/javase/8/docs/jre/api/net/httpserver/spec/com/sun/net/httpserver/package-summary.html Python: FastAPI + uvicorn The default http package in python does not support multithreading, making it unfair to use in this example Methodology All tests were run using: locust (version 2.32.1) to generate load and graphs Ran using locust --processes -1 to use all available threads Settings used Direct IP connection (i.e. http://192.168.1.1:<port> ) Number of users 10,000 Users/sec 100 Time 5 mins Tasks A single GET request per user to / Load generated on a separate machine Connected via an ethernet 2.5Gbps connection 16 cores, 32 threads 32GB RAM Results Some warnings before reading the results and methodology: This test did not last long enough for lengthy GC's to cause problems 10k concurrent users is largely unreasonable 100 users/sec is also unreasonable, and gives little chance for servers to adapt to load Closer to a DDOS than a typical usage pattern The task itself is incredibly simplistic, and is not reasonable (no DB calls, no template parsing, etc.) * Run 1 is go, run 2 is Java, and run 3 is python Under Load: Language Response times (ms) 50th Percentile Response times (ms) 95th Percentile Requests per second Number of users Link Source Go 6 20 ~4980 10,000 Link Link Python 500 680 ~3650 10,000 Link Link Java 465 2350 ~3550 10,000 Link Link * Response times calculated as \\frac{rt_{max}+rt_{min}}{2} where rt max is the maximum response time under full 10k load, and rt min is the minimum check links in table for more granular details Takeaways Go is by far the most performant for this test In particular the response time is 100x lower on the 50th percentile, which is quite significant Generally Go was able to handle everything, there was 1 spike in response time around ~8k users, but isn't consistent across the tests Python ran much better than I thought There is a bunch of optimizations I can run without making changes (like pypy , or optimization mode ) The response times steadily climbed with python, likely because of background running GC's, if it was left longer we would start to see the top end of that latency Much easier to work with than java Java was dissapointing It started showing first signs of struggling around 9k, but the 95th percentile results are rough compared to python This means your users could be waiting up to 3 seconds before a response is sent, and this is a best case scenario because there isn't even any processing being done I personally find java a pain to work with, I typically \"put up\" with it, because I've been told it has better performance characteristics, I'm not so sure of that anymore","title":"Http-basics"},{"location":"http-basics/#http-basics","text":"This test is just designed to compare a very basic HTTP server from each language. Specifically the stack for each language is: Go: The net/http standard library https://pkg.go.dev/net/http Java: The com.sun.net.httpserver \"standard\" library https://docs.oracle.com/javase/8/docs/jre/api/net/httpserver/spec/com/sun/net/httpserver/package-summary.html Python: FastAPI + uvicorn The default http package in python does not support multithreading, making it unfair to use in this example","title":"HTTP basics"},{"location":"http-basics/#methodology","text":"All tests were run using: locust (version 2.32.1) to generate load and graphs Ran using locust --processes -1 to use all available threads Settings used Direct IP connection (i.e. http://192.168.1.1:<port> ) Number of users 10,000 Users/sec 100 Time 5 mins Tasks A single GET request per user to / Load generated on a separate machine Connected via an ethernet 2.5Gbps connection 16 cores, 32 threads 32GB RAM","title":"Methodology"},{"location":"http-basics/#results","text":"Some warnings before reading the results and methodology: This test did not last long enough for lengthy GC's to cause problems 10k concurrent users is largely unreasonable 100 users/sec is also unreasonable, and gives little chance for servers to adapt to load Closer to a DDOS than a typical usage pattern The task itself is incredibly simplistic, and is not reasonable (no DB calls, no template parsing, etc.) * Run 1 is go, run 2 is Java, and run 3 is python Under Load: Language Response times (ms) 50th Percentile Response times (ms) 95th Percentile Requests per second Number of users Link Source Go 6 20 ~4980 10,000 Link Link Python 500 680 ~3650 10,000 Link Link Java 465 2350 ~3550 10,000 Link Link * Response times calculated as \\frac{rt_{max}+rt_{min}}{2} where rt max is the maximum response time under full 10k load, and rt min is the minimum check links in table for more granular details","title":"Results"},{"location":"http-basics/#takeaways","text":"Go is by far the most performant for this test In particular the response time is 100x lower on the 50th percentile, which is quite significant Generally Go was able to handle everything, there was 1 spike in response time around ~8k users, but isn't consistent across the tests Python ran much better than I thought There is a bunch of optimizations I can run without making changes (like pypy , or optimization mode ) The response times steadily climbed with python, likely because of background running GC's, if it was left longer we would start to see the top end of that latency Much easier to work with than java Java was dissapointing It started showing first signs of struggling around 9k, but the 95th percentile results are rough compared to python This means your users could be waiting up to 3 seconds before a response is sent, and this is a best case scenario because there isn't even any processing being done I personally find java a pain to work with, I typically \"put up\" with it, because I've been told it has better performance characteristics, I'm not so sure of that anymore","title":"Takeaways"},{"location":"sockets/","text":"Sockets This test is just comparing a very naive and simple approach to a multithreaded HTTP server, with a hard coded result. This test doesn't provide a ton of value, besides helping me test how locust worked. Methodology All tests were run using: locust (version 2.32.1) to generate load and graphs Ran using locust --processes -1 to use all available threads Settings used Direct IP connection (i.e. http://192.168.1.1:<port> ) Number of users 2, 500 and 5,000 (separate tests) Users/sec 100 Time 5 mins Tasks A single GET request per user to / Load generated on a separate machine Connected via an ethernet 2.5Gbps connection 16 cores, 32 threads 32GB RAM Results Some warnings before reading the results and methodology: This test did not last long enough for lengthy GC's to cause problems 5k and 2.5k concurrent users on something this simplistic is largely unreasonable 100 users/sec is also unreasonable, and gives little chance for servers to adapt to load Closer to a DDOS than a typical usage pattern The task itself is incredibly simplistic, and is not reasonable (no DB calls, no template parsing, etc.) 5,000 users *Python is run 1, Java is run 2, go is run 3 Under Load : Language Response times (ms) 50th Percentile Response times (ms) 95th Percentile Requests per second Number of users Link Source Go 15 90 ~2,472 5,000 Link Link Python 12 90 ~2,470 5,000 Link Link Java 12 90 ~2,475 5,000 Link Link * Response times calculated as \\frac{rt_{max}+rt_{min}}{2} where rt_{max} is the maximum response time under full 10k load, and rt_{min} is the minimum check links in table for more granular details Takeaways: They're all essentially equivalent, and within margin of error 2,500 users Under Load : Language Response times (ms) 50th Percentile Response times (ms) 95th Percentile Requests per second Number of users Link Source Go 11 79 ~1,250 2,500 Link Link Python 12 60 ~1240 2,500 Link Link Java 12 35 ~1243 2,500 Link Link * Response times calculated as \\frac{rt_{max}+rt_{min}}{2} where rt_{max} is the maximum response time under full 10k load, and rt_{min} is the minimum check links in table for more granular details Takeaways: They're all essentially equivalent, and within margin of error","title":"Sockets"},{"location":"sockets/#sockets","text":"This test is just comparing a very naive and simple approach to a multithreaded HTTP server, with a hard coded result. This test doesn't provide a ton of value, besides helping me test how locust worked.","title":"Sockets"},{"location":"sockets/#methodology","text":"All tests were run using: locust (version 2.32.1) to generate load and graphs Ran using locust --processes -1 to use all available threads Settings used Direct IP connection (i.e. http://192.168.1.1:<port> ) Number of users 2, 500 and 5,000 (separate tests) Users/sec 100 Time 5 mins Tasks A single GET request per user to / Load generated on a separate machine Connected via an ethernet 2.5Gbps connection 16 cores, 32 threads 32GB RAM","title":"Methodology"},{"location":"sockets/#results","text":"Some warnings before reading the results and methodology: This test did not last long enough for lengthy GC's to cause problems 5k and 2.5k concurrent users on something this simplistic is largely unreasonable 100 users/sec is also unreasonable, and gives little chance for servers to adapt to load Closer to a DDOS than a typical usage pattern The task itself is incredibly simplistic, and is not reasonable (no DB calls, no template parsing, etc.)","title":"Results"},{"location":"sockets/#5000-users","text":"*Python is run 1, Java is run 2, go is run 3 Under Load : Language Response times (ms) 50th Percentile Response times (ms) 95th Percentile Requests per second Number of users Link Source Go 15 90 ~2,472 5,000 Link Link Python 12 90 ~2,470 5,000 Link Link Java 12 90 ~2,475 5,000 Link Link * Response times calculated as \\frac{rt_{max}+rt_{min}}{2} where rt_{max} is the maximum response time under full 10k load, and rt_{min} is the minimum check links in table for more granular details Takeaways: They're all essentially equivalent, and within margin of error","title":"5,000 users"},{"location":"sockets/#2500-users","text":"Under Load : Language Response times (ms) 50th Percentile Response times (ms) 95th Percentile Requests per second Number of users Link Source Go 11 79 ~1,250 2,500 Link Link Python 12 60 ~1240 2,500 Link Link Java 12 35 ~1243 2,500 Link Link * Response times calculated as \\frac{rt_{max}+rt_{min}}{2} where rt_{max} is the maximum response time under full 10k load, and rt_{min} is the minimum check links in table for more granular details Takeaways: They're all essentially equivalent, and within margin of error","title":"2,500 users"}]}